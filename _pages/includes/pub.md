{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

# Selected Publications

[//]: # (Check out full publication list at my Google Scholar profile: )

[//]: # (<a href='https://scholar.google.com/citations?user=TsjvwzgAAAAJ&hl=en&authuser=2'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>.)

[//]: # (Check out full publication list at my <a href='https://scholar.google.com/citations?user=TsjvwzgAAAAJ&hl=en&authuser=2'>Google Scholar profile</a>.)

### Out-of-Distribution Generalization:
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2024</div><a href="images/neurips_2024.png"><img src='images/neurips_2024.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">

<b>Vision Transformer Neural Architecture Search for Out-of-Distribution Generalization: Benchmark and Insights</b><br>
<i>Conference on Neural Information Processing Systems (NeurIPS), 2024</i><br>
Sy-Tuyen Ho *, <b>Tuan Van Vo *</b>, Somayeh Ebrahimkhani *, Ngai-Man Cheung <br>
<b>* Co-first authors, Equal contribution<br>
[<a href="https://openreview.net/forum?id=2AIwiIkE0s">NeurIPS</a>]
[<a href="https://github.com/vovantuan1999a/OoD-ViT-NAS">Code (Github)</a>]<br>
<div style="text-align: justify">

</div>
</div>
</div>

### Multimodal Model for Robotic Vision Task:
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICRA 2024</div><a href="images/openad.png"><img src='images/openad.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">

<b>Open-Vocabulary Affordance Detection using Knowledge Distillation and Text-Point Correlation</b><br>
<i>IEEE International Conference on Robotics and Automation (ICRA), 2024 </i><br>
<b>Oral presentation</b><br>
<b>Tuan Van Vo</b>, Minh Nhat Vu, Baoru Huang, Toan Nguyen, Ngan Le, Thieu Vo, Anh Nguyen<br>
[<a href="https://arxiv.org/abs/2309.10932">ICRA</a>]
[<a href="https://github.com/Fsoft-AIC/Open-Vocabulary-Affordance-Detection-using-Knowledge-Distillation-and-Text-Point-Correlation">Code</a>]<br>
<div style="text-align: justify">

</div>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IROS 2024</div><a href="images/iros2024.png"><img src='images/iros2024.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">

<b>Language-driven Grasp Detection with Mask-guided Attention</b><br>
<i>The IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2024</i><br>
<b>Oral presentation</b><br>
<b>Tuan Van Vo</b>, Minh Nhat Vu, Baoru Huang, An Vuong, Ngan Le, Thieu Vo, Anh Nguyen<br>
[<a href="https://arxiv.org/abs/2407.19877">arXiv</a>]
[<a href="">Code (Coming Soon)</a>]<br>
<div style="text-align: justify">

</div>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICRA 2024</div><a href="images/grasp-pose.png"><img src='images/grasp-pose.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">

<b>Language-Conditioned Affordance-Pose Detection in 3D Point Cloud</b><br>
<i>IEEE International Conference on Robotics and Automation (ICRA), 2024</i><br>
<b>Oral presentation</b><br>
Toan Nguyen, Minh Nhat Vu, Baoru Huang, <b>Tuan Van Vo</b>, Vy Truong, Ngan Le, Thieu Vo, Bac Le, Anh Nguyen<br>
[<a href="https://arxiv.org/abs/2309.10911">ICRA</a>]
[<a href="https://github.com/Fsoft-AIC/Language-Conditioned-Affordance-Pose-Detection-in-3D-Point-Clouds">Code</a>]<br>
<div style="text-align: justify">

</div>
</div>
</div>

### Semi-Supervised Learning for Medical Segmentation:
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">BMVC 2022</div><a href="images/BMVC.png"><img src='images/BMVC.png' alt="sym" width="100%"></a></div></div>
<div class='paper-box-text' markdown="1">

<b>Dual consistency assisted multi-confident learning for the hepatic vessel segmentation using noisy labels</b><br>
<i>The British Machine Vision Conference (BMVC), 2022</i><br>
Nam Phuong Nguyen * , <b>Tuan Van Vo *</b>, Soan TM Duong, Chanh D Tr Nguyen, Trung Bui, Steven QH Truong<br>
<b> * Co-first authors, Equal contribution<br>
[<a href="https://bmvc2022.mpi-inf.mpg.de/0725.pdf">BMVC</a>]
[<a href="https://github.com/VinBrainJSC/DualConsistency_Mutil-CL">Code</a>]<br>
<div style="text-align: justify">

</div>
</div>
</div>



